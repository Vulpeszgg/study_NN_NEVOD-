{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Lmifnko5KQh0wPco3h6zdde-v0oj1LGa",
      "authorship_tag": "ABX9TyMweB+lfmCLgYSsX/hWfsHg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5YHO7UM1FRq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Загрузка данных\n",
        "data = np.load('images_r.npy')\n",
        "labels = np.load('masks_r.npy')\n",
        "\n",
        "# Разбиение данных на train и test\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Преобразование данных в тензоры\n",
        "train_data = torch.Tensor(train_data)\n",
        "train_labels = torch.Tensor(train_labels)\n",
        "test_data = torch.Tensor(test_data)\n",
        "test_labels = torch.Tensor(test_labels)\n",
        "\n",
        "# Определение модели\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedEncoderDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedEncoderDecoder, self).__init__()\n",
        "\n",
        "        # Энкодер\n",
        "        self.encoder_conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.encoder_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.encoder_conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.encoder_conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.dropout1 = nn.Dropout2d(p=0.2)\n",
        "        self.encoder_pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Декодер\n",
        "        self.decoder_upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.decoder_conv1 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        self.decoder_conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(32)\n",
        "        self.decoder_conv3 = nn.Conv2d(32, 16, 3, padding=1)\n",
        "        self.bn7 = nn.BatchNorm2d(16)\n",
        "        self.dropout2 = nn.Dropout2d(p=0.2)\n",
        "        self.decoder_conv4 = nn.Conv2d(16, 1, 3, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Энкодер\n",
        "        x = F.relu(self.bn1(self.encoder_conv1(x)))\n",
        "        x = F.relu(self.bn2(self.encoder_conv2(x)))\n",
        "        x = self.encoder_pool(F.relu(self.bn3(self.encoder_conv3(x))))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.encoder_pool(F.relu(self.bn4(self.encoder_conv4(x))))\n",
        "\n",
        "        # Декодер\n",
        "        x = self.decoder_upsample(x)\n",
        "        x = F.relu(self.bn5(self.decoder_conv1(x)))\n",
        "        x = self.decoder_upsample(x)\n",
        "        x = F.relu(self.bn6(self.decoder_conv2(x)))\n",
        "        x = F.relu(self.bn7(self.decoder_conv3(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = torch.sigmoid(self.decoder_conv4(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Создание экземпляра модели и определение функции потерь и оптимизатора\n",
        "model = ImprovedEncoderDecoder()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Обучение модели\n",
        "# Обучение модели\n",
        "batch_size = 16\n",
        "epochs = 15\n",
        "num_batches = len(train_data) // batch_size\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_recall = 0.0\n",
        "    running_precision = 0.0\n",
        "    for i in range(num_batches):\n",
        "        # Обнуление градиентов перед каждой итерацией обучения\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        batch_data = train_data[i*batch_size:(i+1)*batch_size]\n",
        "        batch_labels = train_labels[i*batch_size:(i+1)*batch_size]\n",
        "        outputs = model(batch_data.unsqueeze(1))\n",
        "        loss = criterion(outputs, batch_labels.unsqueeze(1))\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Обратный проход и оптимизация\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Расчет метрик recall и precision\n",
        "        with torch.no_grad():\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            true_positives = (predicted * batch_labels.unsqueeze(1)).sum()\n",
        "            false_positives = (predicted * (1 - batch_labels.unsqueeze(1))).sum()\n",
        "            false_negatives = ((1 - predicted) * batch_labels.unsqueeze(1)).sum()\n",
        "            recall = true_positives / (true_positives + false_negatives)\n",
        "            precision = true_positives / (true_positives + false_positives)\n",
        "            running_recall += recall.item()\n",
        "            running_precision += precision.item()\n",
        "\n",
        "    # Вывод loss, recall и precision на каждой эпохе\n",
        "    print(f\"Epoch {epoch + 1} loss: {running_loss / num_batches}, recall: {running_recall / num_batches}, precision: {running_precision / num_batches}\")\n",
        "\n",
        "# Тестирование модели\n",
        "# Тестирование модели\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = (model(test_data.unsqueeze(1)) > 0.5).float()\n",
        "    test_loss = criterion(test_outputs, test_labels.unsqueeze(1))\n",
        "    print(f\"Test loss: {test_loss.item()}\")\n",
        "    batch_size = 16\n",
        "    num_batches = len(test_data) // batch_size\n",
        "    running_recall = 0.0\n",
        "    running_precision = 0.0\n",
        "    false_positive_pixels = 0  # счетчик пикселей, на которых был ненастоящий сигнал на входных данных, но на выходных данных его нет\n",
        "    false_positive_total_pixels = 0  # общее количество пикселей с ненастоящим сигналом на входных данных\n",
        "    for i in range(num_batches):\n",
        "        batch_data = test_data[i * batch_size:(i + 1) * batch_size]\n",
        "        batch_labels = test_labels[i * batch_size:(i + 1) * batch_size]\n",
        "        outputs = model(batch_data.unsqueeze(1))\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        true_positives = (predicted * batch_labels.unsqueeze(1)).sum()\n",
        "        false_positives = (predicted * (1 - batch_labels.unsqueeze(1))).sum()\n",
        "        false_negatives = ((1 - predicted) * batch_labels.unsqueeze(1)).sum()\n",
        "        recall = true_positives / (true_positives + false_negatives)\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "        running_recall += recall.item()\n",
        "        running_precision += precision.item()\n",
        "        false_positive_pixels += ((batch_data == 1) & (predicted == 0)).sum()\n",
        "        false_positive_total_pixels += ((batch_data == 1) & (batch_labels == 0)).sum()\n",
        "\n",
        "\n",
        "    print(f\"Test recall: {running_recall / num_batches}, Test precision: {running_precision / num_batches}\")\n",
        "    false_positive_rate = false_positive_pixels / false_positive_total_pixels\n",
        "    print(f\"False positive rate: {false_positive_rate}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "total_true_removed_signals = 0\n",
        "total_predicted_removed_signals = 0\n",
        "total_true_signals = 0\n",
        "total_input_true_removed_signals = 0\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    # plt.matshow(test_data[i].cpu(), aspect='auto')\n",
        "    # plt.title(\"Input\")\n",
        "    # plt.show()\n",
        "\n",
        "    # plt.matshow(test_labels[i].cpu(), aspect='auto')\n",
        "    # plt.title(\"True Mask\")\n",
        "    # plt.show()\n",
        "\n",
        "    # plt.matshow((test_outputs[i, 0] > 0.5).float().cpu(), aspect='auto')\n",
        "    # plt.title(\"Predicted Mask\")\n",
        "    # plt.show()\n",
        "\n",
        "    input_signal = test_data[i].cpu().numpy()\n",
        "    true_mask = test_labels[i].cpu().numpy()\n",
        "    predicted_mask = (test_outputs[i, 0] > 0.5).float().cpu().numpy()\n",
        "\n",
        "    # Calculate the number of signals on each line\n",
        "    print(f\"Number of signals on each line:\")\n",
        "    for j in range(input_signal.shape[0]):\n",
        "        line_input_signals = 0\n",
        "        line_true_removed_signals = 0\n",
        "        line_predicted_removed_signals = 0\n",
        "\n",
        "        # Track the start of a continuous sequence of 1s\n",
        "        start = -1\n",
        "        for k in range(input_signal.shape[1]):\n",
        "            if input_signal[j, k] == 1:\n",
        "                if start == -1:\n",
        "                    start = k\n",
        "            else:\n",
        "                if start != -1:\n",
        "                    line_input_signals += 1\n",
        "                    if np.all(true_mask[j, start:k] == 0):\n",
        "                        line_true_removed_signals += 1\n",
        "                        if np.all(predicted_mask[j, start:k] == 0):\n",
        "                            line_predicted_removed_signals += 1\n",
        "                    start = -1\n",
        "\n",
        "        # Check if there is an ongoing sequence at the end\n",
        "        if start != -1:\n",
        "            line_input_signals += 1\n",
        "            if np.all(true_mask[j, start:] == 0):\n",
        "                line_true_removed_signals += 1\n",
        "                if np.all(predicted_mask[j, start:] == 0):\n",
        "                    line_predicted_removed_signals += 1\n",
        "\n",
        "        print(f\"Line {j+1}: Input Signals: {line_input_signals}, True Removed Signals: {line_true_removed_signals}, Predicted Removed Signals: {line_predicted_removed_signals}\")\n",
        "\n",
        "        # Accumulate the total number of True Removed Signals and Predicted Removed Signals\n",
        "        total_true_removed_signals += line_true_removed_signals\n",
        "        total_predicted_removed_signals += line_predicted_removed_signals\n",
        "\n",
        "        # Accumulate the total number of True Signals where input=1, true=1, and predicted=0\n",
        "        total_input_true_removed_signals += np.sum((input_signal[j, :] == 1) & (true_mask[j, :] == 1) & (predicted_mask[j, :] == 0))\n",
        "\n",
        "    # Calculate the total number of True Signals\n",
        "    total_true_signals += np.sum(true_mask == 1)\n",
        "\n",
        "    print()\n",
        "\n",
        "# Calculate the percentage of Predicted Removed Signals over True Removed Signals\n",
        "percent_removed_predicted_true = (total_predicted_removed_signals / total_true_removed_signals) * 100\n",
        "percent_removed_input_true = (total_input_true_removed_signals / total_true_signals) * 100\n",
        "\n",
        "print(f\"Total True Removed Signals: {total_true_removed_signals}\")\n",
        "print(f\"Total Predicted Removed Signals: {total_predicted_removed_signals}\")\n",
        "print(f\"Percentage of Predicted Removed Signals / True Removed Signals: {percent_removed_predicted_true}%\")\n",
        "print(f\"Percentage of Input True Signals Removed / True Signals: {percent_removed_input_true}%\")\n"
      ]
    }
  ]
}